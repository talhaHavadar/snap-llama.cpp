name: llama-cpp
base: core26
version: "b7616-1"
summary: Snap package for llama.cpp - LLM inference in C/C++
description: |
  This snap provides llama.cpp with different backends like HIP (for AMD GPU)
  using snap components.
grade: devel
confinement: devmode
package-repositories:
  - type: apt
    components:
      - main
    suites:
      - resolute
    key-id: 9272F44EA10223C73B884BADB35AA5B4E400B24A
    url: https://ppa.launchpadcontent.net/tchavadar/rocm-with-llvm-21/ubuntu
environment:
  # Set path to snap components
  SNAP_COMPONENTS: /snap/$SNAP_INSTANCE_NAME/components/$SNAP_REVISION
  # To find shared libraries that are staged and moved to components
  ARCH_TRIPLET: $CRAFT_ARCH_TRIPLET_BUILD_FOR
components:
  hip:
    type: standard
    summary: llama.cpp with HIP backend
    description: Optimized for inference on AMD GPUs
apps:
  llama-cpp:
    command: bin/cli-wrapper
    plugs:
      - home
parts:
  cli:
    plugin: dump
    source: .
    stage:
      - bin/cli-wrapper
    organize:
      cli.sh: bin/cli-wrapper
  component-local-files:
    plugin: dump
    source: components
    organize:
      "hip": (component/hip)
  llama-cpp-hip:
    source: https://github.com/ggml-org/llama.cpp.git
    source-tag: b7616
    source-depth: 1
    build-packages:
      - rocm-cmake
      - hipcc
      - libhipblas-dev
      - librocblas-dev
      - libcurl4-openssl-dev
    stage-packages:
      - libcurl4t64
      - libssl3t64
      - libgomp1
      - libhipblas3
      - librocblas5
    plugin: cmake
    override-build: |
      export HIPCXX="$(hipconfig -l)/clang"
      export HIP_PATH="$(hipconfig -R)"
      craftctl default
    cmake-parameters:
      - -DGGML_HIP=ON
      - -DGPU_TARGETS='gfx90a;gfx942;gfx1030;gfx1100;gfx1151;gfx11-generic;gfx1200;gfx1201'
      - -DCMAKE_BUILD_TYPE=Release
      # - -DGGML_HIP_ROCWMMA_FATTN=ON # needs rocwmma-dev package
    organize:
      # move everything, including the staged packages
      "*": (component/hip)
